"""
å‘é‡åŒ–ç®¡çº¿æ¨¡å—

è´Ÿè´£å°†æ¸¸æˆæ•°æ®è½¬æ¢ä¸ºå‘é‡å¹¶å­˜å…¥å‘é‡æ•°æ®åº“
æ ¸å¿ƒæµç¨‹ï¼šæ–‡æœ¬èåˆ â†’ å‘é‡ç”Ÿæˆ â†’ æ‰¹é‡å…¥åº“
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional
from pathlib import Path
import yaml
from tqdm import tqdm

from src.models.model_manager import ModelManager
from src.vectordb.chroma_store import ChromaVectorStore
from src.data_processing.feature_engineer import FeatureEngineer
from src.utils.logger import setup_logger


class GameVectorizer:
    """æ¸¸æˆæ•°æ®å‘é‡åŒ–å™¨
    
    å°†æ ‡å‡†åŒ–åçš„æ¸¸æˆæ•°æ®è½¬æ¢ä¸ºå‘é‡å¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    """
    
    def __init__(
        self,
        vectorization_config_path: str = "config/vectorization.yaml",
        models_config_path: str = "config/models.yaml"
    ):
        """
        åˆå§‹åŒ–å‘é‡åŒ–å™¨
        
        Args:
            vectorization_config_path: å‘é‡åŒ–é…ç½®æ–‡ä»¶è·¯å¾„
            models_config_path: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.logger = setup_logger("GameVectorizer")
        
        # ä¿å­˜é…ç½®è·¯å¾„
        self.models_config_path = models_config_path
        
        # åŠ è½½é…ç½®
        self.vec_config = self._load_config(vectorization_config_path)
        self.model_config = self._load_config(models_config_path)
        
        # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨ï¼ˆä¼ é€’é…ç½®æ–‡ä»¶è·¯å¾„ï¼‰
        self.logger.info("ğŸ¤– åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨...")
        self.model_manager = ModelManager(config_path=self.models_config_path)
        
        # åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹å™¨
        self.logger.info("âš™ï¸ åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹å™¨...")
        self.feature_engineer = FeatureEngineer(
            config=self.vec_config.get("feature_engineering", {})
        )
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        self.logger.info("ğŸ’¾ åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        vectordb_config = self.vec_config.get("vectordb", {})
        self.vector_store = ChromaVectorStore(
            persist_directory=self.model_config.get("vectordb", {}).get("persist_directory", "./data/vector_db"),
            collection_name=vectordb_config.get("collection_name", "steam_games"),
            distance_metric=vectordb_config.get("distance_metric", "cosine")
        )
        
        self.logger.info("âœ… å‘é‡åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        åŠ è½½YAMLé…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸
        """
        config_path = Path(config_path)
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def fuse_text(self, row: pd.Series) -> str:
        """
        æ ¹æ®æ¨¡æ¿èåˆæ–‡æœ¬
        
        Args:
            row: DataFrameçš„ä¸€è¡Œæ•°æ®
            
        Returns:
            èåˆåçš„æ–‡æœ¬å­—ç¬¦ä¸²
        """
        template = self.vec_config["text_fusion"]["template"]
        fields = self.vec_config["text_fusion"]["fields"] if "fields" in self.vec_config["text_fusion"] else []
        
        # å‡†å¤‡å¡«å……æ•°æ®ï¼ˆå¤„ç†ç¼ºå¤±å€¼ï¼‰
        fill_data = {}
        for field in fields:
            value = row.get(field, '')
            # å¤„ç†NaNå’ŒNone
            if pd.isna(value) or value is None:
                value = ''
            fill_data[field] = str(value)
        
        # å¦‚æœæ¨¡æ¿ä¸­æœ‰å…¶ä»–å­—æ®µï¼ˆå¦‚è¡ç”Ÿç‰¹å¾ï¼‰ï¼Œä¹Ÿæ·»åŠ è¿›å»
        for key in row.index:
            if key not in fill_data:
                value = row[key]
                if pd.isna(value) or value is None:
                    value = ''
                fill_data[key] = str(value)
        
        try:
            # å¡«å……æ¨¡æ¿
            fused_text = template.format(**fill_data)
            return fused_text.strip()
        except KeyError as e:
            self.logger.warning(f"æ–‡æœ¬èåˆç¼ºå°‘å­—æ®µ {e}, AppID: {row.get('AppID', 'Unknown')}")
            # é™çº§æ–¹æ¡ˆï¼šåªä½¿ç”¨åç§°å’Œæè¿°
            name = row.get('Name', '')
            desc = row.get('About the game', '')
            return f"Game: {name}\nDescription: {desc}".strip()
        except Exception as e:
            self.logger.error(f"æ–‡æœ¬èåˆå¤±è´¥: {e}, AppID: {row.get('AppID', 'Unknown')}")
            return row.get('Name', 'Unknown Game')
    
    def prepare_metadata(self, row: pd.Series) -> Dict[str, Any]:
        """
        å‡†å¤‡metadataå­—å…¸
        
        Args:
            row: DataFrameçš„ä¸€è¡Œæ•°æ®
            
        Returns:
            æ¸…æ´—åçš„metadataå­—å…¸ï¼ˆç¬¦åˆChromaDBè¦æ±‚ï¼‰
        """
        metadata = {}
        
        # è·å–metadataå­—æ®µé…ç½®
        metadata_config = self.vec_config.get("metadata_fields", {})
        
        # åˆå¹¶æ‰€æœ‰å­—æ®µç±»å‹
        all_fields = []
        for category in ["required", "text", "numeric", "boolean", "temporal", "other"]:
            if category in metadata_config:
                all_fields.extend(metadata_config[category])
        
        # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨æ‰€æœ‰åˆ—
        if not all_fields:
            all_fields = row.index.tolist()
        
        # å¡«å……metadata
        for field in all_fields:
            if field not in row.index:
                continue
            
            value = row[field]
            
            # è·³è¿‡NaNå€¼
            if pd.isna(value):
                continue
            
            # ç±»å‹è½¬æ¢ï¼ˆChromaDBè¦æ±‚metadataå€¼å¿…é¡»æ˜¯åŸºæœ¬ç±»å‹ï¼‰
            if isinstance(value, (np.integer, np.int64, np.int32)):
                metadata[field] = int(value)
            elif isinstance(value, (np.floating, np.float64, np.float32)):
                # å°†NaNå’Œinfè½¬ä¸º0
                if np.isnan(value) or np.isinf(value):
                    metadata[field] = 0.0
                else:
                    metadata[field] = float(value)
            elif isinstance(value, (bool, np.bool_)):
                metadata[field] = bool(value)
            elif isinstance(value, str):
                metadata[field] = value
            else:
                # å…¶ä»–ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²
                metadata[field] = str(value)
        
        return metadata
    
    def vectorize_batch(
        self,
        df: pd.DataFrame,
        batch_size: Optional[int] = None
    ) -> None:
        """
        æ‰¹é‡å‘é‡åŒ–å¹¶å­˜å…¥å‘é‡æ•°æ®åº“
        
        Args:
            df: å·²æ ‡å‡†åŒ–ä¸”å®Œæˆç‰¹å¾å·¥ç¨‹çš„DataFrame
            batch_size: æ‰¹å¤„ç†å¤§å°ï¼ŒNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶çš„å€¼
        """
        if batch_size is None:
            batch_size = self.vec_config.get("batch_processing", {}).get("chunk_size", 32)
        
        total = len(df)
        self.logger.info(f"ğŸš€ å¼€å§‹å‘é‡åŒ– {total} æ¡æ¸¸æˆæ•°æ®...")
        
        # è¿›åº¦æ¡é…ç½®
        show_progress = self.vec_config.get("batch_processing", {}).get("show_progress", True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        success_count = 0
        error_count = 0
        
        # åˆ†æ‰¹å¤„ç†
        iterator = range(0, total, batch_size)
        if show_progress:
            iterator = tqdm(iterator, desc="å‘é‡åŒ–è¿›åº¦", unit="batch")
        
        for i in iterator:
            batch_df = df.iloc[i:i+batch_size]
            
            try:
                # 1. æ–‡æœ¬èåˆ
                documents = batch_df.apply(self.fuse_text, axis=1).tolist()
                
                # 2. ç”Ÿæˆå‘é‡
                self.logger.debug(f"æ­£åœ¨ç”Ÿæˆå‘é‡ (batch {i//batch_size + 1})...")
                embeddings = self.model_manager.encode_text(
                    texts=documents,
                    is_query=False
                )
                
                # 3. å‡†å¤‡metadata
                metadatas = batch_df.apply(self.prepare_metadata, axis=1).tolist()
                
                # 4. å‡†å¤‡IDsï¼ˆä½¿ç”¨AppIDï¼‰
                if 'AppID' in batch_df.columns:
                    ids = batch_df['AppID'].astype(str).tolist()
                else:
                    # å¦‚æœæ²¡æœ‰AppIDï¼Œä½¿ç”¨ç´¢å¼•
                    ids = [f"game_{idx}" for idx in batch_df.index]
                
                # 5. å…¥åº“
                self.vector_store.add(
                    ids=ids,
                    documents=documents,
                    metadatas=metadatas,
                    embeddings=embeddings
                )
                
                success_count += len(batch_df)
                
                # æ›´æ–°è¿›åº¦ä¿¡æ¯
                if show_progress and isinstance(iterator, tqdm):
                    iterator.set_postfix({
                        'success': success_count,
                        'errors': error_count
                    })
                
            except Exception as e:
                error_count += len(batch_df)
                self.logger.error(f"âŒ æ‰¹æ¬¡ {i//batch_size + 1} å…¥åº“å¤±è´¥: {e}")
                
                # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ç»§ç»­
                continue_on_error = self.vec_config.get("batch_processing", {}).get("continue_on_error", True)
                if not continue_on_error:
                    raise
        
        # æŒä¹…åŒ–
        self.logger.info("ğŸ’¾ æŒä¹…åŒ–å‘é‡æ•°æ®åº“...")
        self.vector_store.persist()
        
        # æœ€ç»ˆç»Ÿè®¡
        final_count = self.vector_store.get_count()
        self.logger.info(f"âœ… å‘é‡åŒ–å®Œæˆï¼")
        self.logger.info(f"   - æˆåŠŸ: {success_count} æ¡")
        self.logger.info(f"   - å¤±è´¥: {error_count} æ¡")
        self.logger.info(f"   - æ•°æ®åº“æ€»æ•°: {final_count} æ¡")
    
    def test_query(self, query_text: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        self.logger.info(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: '{query_text}'")
        
        # 1. å°†æŸ¥è¯¢æ–‡æœ¬è½¬ä¸ºå‘é‡
        query_embedding = self.model_manager.encode_text(
            texts=query_text,
            is_query=True
        )
        
        # 2. ä½¿ç”¨å‘é‡æŸ¥è¯¢
        results = self.vector_store.query(
            query_embeddings=query_embedding,
            top_k=top_k
        )
        
        for i, result in enumerate(results, 1):
            metadata = result.get('metadata', {})
            distance = result.get('distance', 0)
            self.logger.info(f"  {i}. {metadata.get('Name', 'Unknown')} (è·ç¦»: {distance:.4f})")
        
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        count = self.vector_store.get_count()
        
        stats = {
            'total_documents': count,
            'collection_name': self.vector_store.collection.name,
            'distance_metric': self.vec_config.get("vectordb", {}).get("distance_metric", "cosine"),
            'embedding_dimension': self.vec_config.get("embedding", {}).get("dimension", 384)
        }
        
        return stats


class VectorizationPipeline:
    """å®Œæ•´çš„å‘é‡åŒ–ç®¡çº¿
    
    æ•´åˆæ•°æ®åŠ è½½ã€æ ‡å‡†åŒ–ã€ç‰¹å¾å·¥ç¨‹ã€å‘é‡åŒ–çš„å®Œæ•´æµç¨‹
    """
    
    def __init__(
        self,
        vectorization_config_path: str = "config/vectorization.yaml",
        models_config_path: str = "config/models.yaml"
    ):
        """
        åˆå§‹åŒ–å‘é‡åŒ–ç®¡çº¿
        
        Args:
            vectorization_config_path: å‘é‡åŒ–é…ç½®æ–‡ä»¶è·¯å¾„
            models_config_path: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.logger = setup_logger("VectorizationPipeline")
        
        # åŠ è½½é…ç½®
        self.vec_config = self._load_config(vectorization_config_path)
        
        # åˆå§‹åŒ–å‘é‡åŒ–å™¨
        self.vectorizer = GameVectorizer(
            vectorization_config_path=vectorization_config_path,
            models_config_path=models_config_path
        )
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def run(
        self,
        input_data: pd.DataFrame,
        batch_size: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„å‘é‡åŒ–ç®¡çº¿
        
        Args:
            input_data: å·²æ ‡å‡†åŒ–ä¸”å®Œæˆç‰¹å¾å·¥ç¨‹çš„æ•°æ®
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            æ‰§è¡Œç»“æœç»Ÿè®¡
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ å¼€å§‹å‘é‡åŒ–ç®¡çº¿")
        self.logger.info("=" * 60)
        
        # æ•°æ®éªŒè¯
        self.logger.info(f"ğŸ“Š è¾“å…¥æ•°æ®: {len(input_data)} æ¡")
        
        # å‘é‡åŒ–
        self.vectorizer.vectorize_batch(input_data, batch_size=batch_size)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.vectorizer.get_statistics()
        
        self.logger.info("=" * 60)
        self.logger.info("âœ… å‘é‡åŒ–ç®¡çº¿å®Œæˆ")
        self.logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        for key, value in stats.items():
            self.logger.info(f"   - {key}: {value}")
        self.logger.info("=" * 60)
        
        return stats


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import sys
    from pathlib import Path
    
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    project_root = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(project_root))
    
    # åˆ›å»ºå‘é‡åŒ–å™¨
    vectorizer = GameVectorizer()
    
    # æµ‹è¯•æŸ¥è¯¢
    vectorizer.test_query("å¼€æ”¾ä¸–ç•Œè§’è‰²æ‰®æ¼”æ¸¸æˆ", top_k=3)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = vectorizer.get_statistics()
    print("\nç»Ÿè®¡ä¿¡æ¯:")
    for k, v in stats.items():
        print(f"  {k}: {v}")
