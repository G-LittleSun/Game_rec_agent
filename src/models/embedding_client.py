"""
Embedding æ¨¡å‹å®¢æˆ·ç«¯
ä½¿ç”¨ sentence-transformers è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
"""
import torch
import numpy as np
from typing import List, Union
from sentence_transformers import SentenceTransformer
from src.utils.logger import setup_logger


class EmbeddingClient:
    """Embeddingæ¨¡å‹å®¢æˆ·ç«¯"""
    
    def __init__(
        self,
        model_name: str = "BAAI/bge-large-zh-v1.5",
        device: str = "cuda",
        batch_size: int = 32,
        max_length: int = 512,
        normalize_embeddings: bool = True,
        cache_dir: str = "./data/model_cache"
    ):
        """
        åˆå§‹åŒ–Embeddingå®¢æˆ·ç«¯
        
        Args:
            model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„
            device: è¿è¡Œè®¾å¤‡ (cuda/cpu/mps)
            batch_size: æ‰¹å¤„ç†å¤§å°
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
            normalize_embeddings: æ˜¯å¦å½’ä¸€åŒ–å‘é‡
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
        """
        self.model_name = model_name
        self.batch_size = batch_size
        self.max_length = max_length
        self.normalize_embeddings = normalize_embeddings
        
        # è®¾ç½®è®¾å¤‡
        if device == "cuda" and not torch.cuda.is_available():
            device = "cpu"
            print("âš ï¸ CUDAä¸å¯ç”¨,ä½¿ç”¨CPU")
        elif device == "mps" and not torch.backends.mps.is_available():
            device = "cpu"
            print("âš ï¸ MPSä¸å¯ç”¨,ä½¿ç”¨CPU")
        
        self.device = device
        

        
        self.logger = setup_logger("EmbeddingClient")
        
        # åŠ è½½æ¨¡å‹
        self.logger.info(f"ğŸ”„ åŠ è½½Embeddingæ¨¡å‹: {model_name}")
        self.model = SentenceTransformer(
            model_name,
            device=device,
            cache_folder=cache_dir
        )
        self.logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ,è®¾å¤‡: {device}")
    
    def encode(
        self,
        texts: Union[str, List[str]],
        batch_size: int = None,
        show_progress: bool = False,
        convert_to_numpy: bool = True
    ) -> Union[np.ndarray, torch.Tensor]:
        """
        å°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡
        
        Args:
            texts: å•ä¸ªæ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°,é»˜è®¤ä½¿ç”¨åˆå§‹åŒ–æ—¶çš„å€¼
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            convert_to_numpy: æ˜¯å¦è½¬æ¢ä¸ºnumpyæ•°ç»„
        
        Returns:
            æ–‡æœ¬å‘é‡,å½¢çŠ¶ä¸º (n_texts, embedding_dim)
        """
        # å¤„ç†å•ä¸ªæ–‡æœ¬
        if isinstance(texts, str):
            texts = [texts]
        
        if batch_size is None:
            batch_size = self.batch_size
        
        # ç¼–ç 
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=show_progress,
            normalize_embeddings=self.normalize_embeddings,
            convert_to_numpy=convert_to_numpy,
            device=self.device
        )
        
        return embeddings
    
    def encode_queries(self, queries: Union[str, List[str]], **kwargs) -> np.ndarray:
        """
        ç¼–ç æŸ¥è¯¢æ–‡æœ¬(ä¸ºå…¼å®¹ä¸åŒæ¨¡å‹,å¯æ·»åŠ ç‰¹æ®Šå¤„ç†)
        
        Args:
            queries: æŸ¥è¯¢æ–‡æœ¬
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            æŸ¥è¯¢å‘é‡
        """
        # BGEæ¨¡å‹å»ºè®®ä¸ºæŸ¥è¯¢æ·»åŠ å‰ç¼€
        if "bge" in self.model_name.lower():
            if isinstance(queries, str):
                queries = f"ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« :{queries}"
            else:
                queries = [f"ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« :{q}" for q in queries]
        
        return self.encode(queries, **kwargs)
    
    def encode_corpus(self, corpus: List[str], **kwargs) -> np.ndarray:
        """
        ç¼–ç è¯­æ–™åº“æ–‡æœ¬
        
        Args:
            corpus: æ–‡æ¡£åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            æ–‡æ¡£å‘é‡
        """
        # è¯­æ–™åº“ä¸éœ€è¦æ·»åŠ å‰ç¼€
        return self.encode(corpus, **kwargs)
    
    def similarity(
        self,
        embeddings1: np.ndarray,
        embeddings2: np.ndarray,
        metric: str = "cosine"
    ) -> np.ndarray:
        """
        è®¡ç®—å‘é‡ç›¸ä¼¼åº¦
        
        Args:
            embeddings1: ç¬¬ä¸€ç»„å‘é‡
            embeddings2: ç¬¬äºŒç»„å‘é‡
            metric: ç›¸ä¼¼åº¦åº¦é‡ (cosine/dot/euclidean)
        
        Returns:
            ç›¸ä¼¼åº¦çŸ©é˜µ
        """
        if metric == "cosine":
            # ä½™å¼¦ç›¸ä¼¼åº¦
            return np.dot(embeddings1, embeddings2.T)
        elif metric == "dot":
            # ç‚¹ç§¯
            return np.dot(embeddings1, embeddings2.T)
        elif metric == "euclidean":
            # æ¬§æ°è·ç¦»(è½¬æ¢ä¸ºç›¸ä¼¼åº¦)
            distances = np.linalg.norm(
                embeddings1[:, np.newaxis] - embeddings2[np.newaxis, :],
                axis=2
            )
            return 1 / (1 + distances)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç›¸ä¼¼åº¦åº¦é‡: {metric}")
    
    def get_embedding_dim(self) -> int:
        """è·å–å‘é‡ç»´åº¦"""
        return self.model.get_sentence_embedding_dimension()
    
    def switch_model(self, model_name: str, cache_dir: str = None):
        """åˆ‡æ¢æ¨¡å‹"""
        self.logger.info(f"ğŸ”„ åˆ‡æ¢Embeddingæ¨¡å‹: {model_name}")
        if cache_dir is None:
            cache_dir = self.model.cache_folder
        
        self.model_name = model_name
        self.model = SentenceTransformer(
            model_name,
            device=self.device,
            cache_folder=cache_dir
        )
        self.logger.info(f"âœ… æ¨¡å‹åˆ‡æ¢å®Œæˆ")


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = EmbeddingClient(
        model_name="BAAI/bge-base-zh-v1.5",
        device="cuda"  
    )
    
    # ç¼–ç æ–‡æœ¬
    texts = [
        "ã€Šå¡å°”è¾¾ä¼ è¯´:æ—·é‡ä¹‹æ¯ã€‹æ˜¯ä¸€æ¬¾å¼€æ”¾ä¸–ç•Œå†’é™©æ¸¸æˆ",
        "ã€Šè‰¾å°”ç™»æ³•ç¯ã€‹æ˜¯ä¸€æ¬¾é»‘æš—å¥‡å¹»å¼€æ”¾ä¸–ç•ŒRPG",
        "ã€Šæˆ‘çš„ä¸–ç•Œã€‹æ˜¯ä¸€æ¬¾æ²™ç›’å»ºé€ æ¸¸æˆ"
    ]
    
    embeddings = client.encode(texts)
    print(f"å‘é‡å½¢çŠ¶: {embeddings.shape}")
    print(f"å‘é‡ç»´åº¦: {client.get_embedding_dim()}")
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    query = "æ¨èä¸€æ¬¾å¼€æ”¾ä¸–ç•Œæ¸¸æˆ"
    query_emb = client.encode_queries(query)
    
    similarities = client.similarity(query_emb, embeddings)
    print(f"\næŸ¥è¯¢: {query}")
    for i, (text, sim) in enumerate(zip(texts, similarities[0])):
        print(f"{i+1}. [{sim:.4f}] {text}")
    print("/n")